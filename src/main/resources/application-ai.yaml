langchain4j:
  community:
    dashscope:
      # LLM
      chat-model:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: qwen3-max
        temperature: 0.7
      # Streaming LLM
      streaming-chat-model:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: qwen3-max
        temperature: 0.7
      # Embedding model
      embedding-model:
        api-key: ${DASHSCOPE_API_KEY}
        model-name: text-embedding-v3
        dimensions: 1024

# Embedding model - PgVector
pgvector:
  host: ${PGVECTOR_HOST}
  port: ${PGVECTOR_PORT}
  database: ${PGVECTOR_DATABASE}
  user: ${PGVECTOR_USER}
  password: ${PGVECTOR_PASSWORD}
  table: ${PGVECTOR_TABLE}

# chat config
chat:
  compress:
    enabled: true
    maxTotalTokens: 6000
    recentRawCount: 10
    minMessagesToCompress: 20

tts:
  qwen:
    enabled: ${TTS_QWEN_ENABLED:true}
    url: ${TTS_QWEN_URL:wss://dashscope.aliyuncs.com/api-ws/v1/realtime}
    model: ${TTS_QWEN_MODEL:qwen3-tts-flash-realtime}
    voice: ${TTS_QWEN_VOICE:Cherry}
    mode: ${TTS_QWEN_MODE:server_commit}
    format: ${TTS_QWEN_FORMAT:PCM_24000HZ_MONO_16BIT}

mcp:
  search-link: ${SEARCH_MCP_LINK}